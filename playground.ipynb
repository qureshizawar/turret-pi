{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images from camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #For Image processing \n",
    "import numpy as np #For converting Images to Numerical array \n",
    "import os #To handle directories \n",
    "from PIL import Image #Pillow lib for handling images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) #Get vidoe feed from the Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, img = cap.read() # Break video into frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train face recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #For Image processing \n",
    "import numpy as np #For converting Images to Numerical array \n",
    "import os #To handle directories \n",
    "from PIL import Image #Pillow lib for handling images \n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "Face_ID = -1 \n",
    "pev_person_name = \"\"\n",
    "y_ID = []\n",
    "x_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Face_Images = os.path.join(os.getcwd(), \"Faces\") #Tell the program where we have saved the face images \n",
    "print (Face_Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(Face_Images): #go to the face image directory \n",
    "\tfor file in files: #check every directory in it \n",
    "\t\tif file.endswith(\"jpeg\") or file.endswith(\"jpg\") or file.endswith(\"png\"): #for image files ending with jpeg,jpg or png \n",
    "\t\t\tpath = os.path.join(root, file)\n",
    "\t\t\tperson_name = os.path.basename(root)\n",
    "\t\t\tprint(path, person_name)\n",
    "\n",
    "\t\t\t\n",
    "\t\t\tif pev_person_name!=person_name: #Check if the name of person has changed \n",
    "\t\t\t\tFace_ID=Face_ID+1 #If yes increment the ID count \n",
    "\t\t\t\tpev_person_name = person_name\n",
    "\n",
    "\t\t\t\n",
    "\t\t\tGery_Image = Image.open(path).convert(\"L\") # convert the image to greysclae using Pillow\n",
    "\t\t\tCrop_Image = Gery_Image.resize( (550,550) , Image.ANTIALIAS) #Crop the Grey Image to 550*550 (Make sure your face is in the center in all image)\n",
    "\t\t\tFinal_Image = np.array(Crop_Image, \"uint8\")\n",
    "\t\t\t#print(Numpy_Image)\n",
    "\t\t\tfaces = face_cascade.detectMultiScale(Final_Image, scaleFactor=1.5, minNeighbors=5) #Detect The face in all sample image \n",
    "\t\t\tprint (Face_ID,faces)\n",
    "\n",
    "\t\t\tfor (x,y,w,h) in faces:\n",
    "\t\t\t\troi = Final_Image[y:y+h, x:x+w] #crop the Region of Interest (ROI)\n",
    "\t\t\t\tx_train.append(roi)\n",
    "\t\t\t\ty_ID.append(Face_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer.train(x_train, np.array(y_ID)) #Create a Matrix of Training data \n",
    "recognizer.save(\"face-trainer.yml\") #Save the matrix as YML file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test face recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #For Image processing \n",
    "import numpy as np #For converting Images to Numerical array \n",
    "import os #To handle directories \n",
    "from PIL import Image #Pillow lib for handling images \n",
    "\n",
    "labels = [\"Elon Musk\"] \n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create() #cv2.createLBPHFaceRecognizer()\n",
    "recognizer.read(\"face-trainer.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) #Get video feed from the Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "\n",
    "    ret, img = cap.read() # Break video into frames \n",
    "    gray  = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #convert Video frame to Greyscale\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5) #Recog. faces\n",
    "    for (x, y, w, h) in faces:\n",
    "    \troi_gray = gray[y:y+h, x:x+w] #Convert Face to greyscale \n",
    "\n",
    "    \tid_, conf = recognizer.predict(roi_gray) #recognize the Face\n",
    "    \n",
    "    \tif conf>=80:\n",
    "    \t\tfont = cv2.FONT_HERSHEY_SIMPLEX #Font style for the name \n",
    "    \t\tname = labels[id_] #Get the name from the List using ID number \n",
    "    \t\tcv2.putText(img, name, (x,y), font, 1, (0,0,255), 2)\n",
    "    \t\n",
    "    \tcv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow('Preview',img) #Display the Video\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "    \tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
